{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import model\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os,timeit\n",
    "import pandas as pd\n",
    "from sklearn import metrics \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "\n",
    "entities_dict = {0: \"Rachel Green\", 1: \"Ross Geller\", 2: \"Chandler Bing\", 3: \"Monica Geller\", 4: \"Joey Tribbiani\", \n",
    "                 5: \"Phoebe Buffay\", 6: \"Others\", 7: \"None\"}\n",
    "\n",
    "def evaluate(mo, model_name = \"\"):\n",
    "\n",
    "    print(\"Evaluating\" + model_name)\n",
    "\n",
    "    # Test input embeddings\n",
    "    test_input = np.load(data_path + 'test_input.npy')\n",
    "\n",
    "    # Test labels in form indexes from entity map\n",
    "    test_label_index = np.load(data_path + 'test_label_index.npy')\n",
    "\n",
    "    # Using gpu if available else cpu\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    total_tokens = 0\n",
    "    correct_tokens = 0\n",
    "\n",
    "    y_correct = torch.Tensor().type(torch.LongTensor)\n",
    "    y_predicted = torch.Tensor().type(torch.LongTensor)\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    for i in range(test_input.shape[0]):\n",
    "\n",
    "        #input sample shape:  (3,25) -> (3,1,25)\n",
    "        #3 words each of dim 25\n",
    "        inp = torch.from_numpy(test_input[i].reshape((-1,1,25))).to(device)\n",
    "\n",
    "        #truth value for input sample: tensor([7, 4, 7])\n",
    "        #each value is prediction class for the word\n",
    "        truth = torch.from_numpy(test_label_index[i])\n",
    "        y_correct = torch.cat((y_correct,truth))\n",
    "\n",
    "        #predcited op shape: torch.Size([3, 8])\n",
    "        out = mo(inp)\n",
    "\n",
    "        #getting class with max probabilities\n",
    "        out = torch.max(out,1)[1]\n",
    "        y_predicted = torch.cat((y_predicted, out))\n",
    "        \n",
    "        assert y_correct.shape == y_predicted.shape, \"**Shape Mismatch**\"\n",
    "        \n",
    "        #Following code is to calculate accuracy for correct token entities\n",
    "\n",
    "        #match each elem separately and returns a tensor of 0/1\n",
    "        check = torch.eq(truth,out)\n",
    "\n",
    "        #summing all 1's i.e. correct predictions\n",
    "        correct_tokens_temp = torch.sum(check).item()\n",
    "        correct_tokens += correct_tokens_temp\n",
    "        \n",
    "        seq_len = check.size()[0]\n",
    "        total_tokens += seq_len\n",
    "\n",
    "    print(\"\\nTotal time taken: %.4f seconds.\" % (timeit.default_timer() - start))\n",
    "\n",
    "    confusion_mat = metrics.confusion_matrix(y_correct, y_predicted)\n",
    "    classification_rpt = metrics.classification_report(y_correct, y_predicted)\n",
    "\n",
    "    #calculating accuracy for each class\n",
    "    accuracy_dict = {}\n",
    "    for i in range(8):\n",
    "        #predictions for i-th entity is in i-th row\n",
    "        total_pred = sum(confusion_mat[i])\n",
    "        correct_pred = confusion_mat[i][i]\n",
    "        accuracy_dict[entities_dict[i]] = round(correct_pred/total_pred, 4)\n",
    "\n",
    "    #print(\"\\n*****Accuracy for each entity:*****\")\n",
    "    #for k,v in accuracy_dict.items():\n",
    "    #    print(\"{0:<20} {1}\".format(k,v))\n",
    "    \n",
    "    token_accuracy = correct_tokens / total_tokens\n",
    "    avg_accuracy = sum(accuracy_dict.values())/len(accuracy_dict)\n",
    "    \n",
    "    #print(\"\\n{0:<40} {1:.4f}\".format(\"Average accuracy per entity: \", avg_accuracy))\n",
    "    #print(\"{0:<40} {1:.4f}\".format(\"Overall accuracy (considering tokens): \", token_accuracy))\n",
    "        \n",
    "    return token_accuracy, avg_accuracy, accuracy_dict, confusion_mat, classification_rpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp_dim = 25\n",
    "hidden_dim = 64\n",
    "n_classes = 8\n",
    "\n",
    "def evaluate_models(model_type, trained_models, msg):\n",
    "    \n",
    "    best_dict = {\"accuracy\": 0,\n",
    "                 \"avg_accuracy\": 0,\n",
    "                 \"model_name\": \"\",\n",
    "                 \"accuracy_dict\": {},\n",
    "                 \"confusion_mat\": \"\"\n",
    "                }\n",
    "    \n",
    "    best_avg_dict = {\"accuracy\": 0,\n",
    "                     \"avg_accuracy\": 0,\n",
    "                     \"model_name\": \"\",\n",
    "                     \"accuracy_dict\": {},\n",
    "                     \"confusion_mat\": \"\"\n",
    "                    }\n",
    "    \n",
    "     \n",
    "    # t: 31-BiLSTM_Loss_0.1387677234002888.pt\n",
    "    for t in trained_models:\n",
    "        mo = model_type(inp_dim, hidden_dim, n_classes)\n",
    "        mo.load_state_dict(torch.load(save_path + t))\n",
    "        \n",
    "        token_accuracy, avg_accuracy, accuracy_dict, confusion_mat, classification_rpt = evaluate(mo, msg + t)\n",
    "\n",
    "        if token_accuracy > best_dict[\"accuracy\"]:\n",
    "            best_dict[\"accuracy\"] = token_accuracy\n",
    "            best_dict[\"avg_accuracy\"] = avg_accuracy\n",
    "            best_dict[\"model_name\"] = t\n",
    "            best_dict[\"accuracy_dict\"] = accuracy_dict\n",
    "            best_dict[\"confusion_mat\"] = confusion_mat\n",
    "\n",
    "        if avg_accuracy > best_avg_dict[\"avg_accuracy\"]:\n",
    "            best_avg_dict[\"accuracy\"] = token_accuracy\n",
    "            best_avg_dict[\"avg_accuracy\"] = avg_accuracy\n",
    "            best_avg_dict[\"model_name\"] = t\n",
    "            best_avg_dict[\"accuracy_dict\"] = accuracy_dict\n",
    "            best_avg_dict[\"confusion_mat\"] = confusion_mat\n",
    "\n",
    "        print(\"-\"*50, \"\\n\")\n",
    "    \n",
    "    return best_dict, best_avg_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Bidirectional LSTM model: 1-BiLSTM_Loss_0.5018732744513754.pt\n",
      "\n",
      "Total time taken: 61.1940 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.2607\n",
      "Ross Geller          0.2599\n",
      "Chandler Bing        0.0\n",
      "Monica Geller        0.0\n",
      "Joey Tribbiani       0.0065\n",
      "Phoebe Buffay        0.1262\n",
      "Others               0.5672\n",
      "None                 0.9931\n",
      "\n",
      "Average accuracy per entity:             0.2767\n",
      "Overall accuracy (considering tokens):   0.8762\n",
      "-------------------------------------------------- \n",
      "\n",
      "Evaluating Bidirectional LSTM model: 11-BiLSTM_Loss_0.1801687417329021.pt\n",
      "\n",
      "Total time taken: 59.9882 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.687\n",
      "Ross Geller          0.5873\n",
      "Chandler Bing        0.5958\n",
      "Monica Geller        0.6367\n",
      "Joey Tribbiani       0.633\n",
      "Phoebe Buffay        0.6485\n",
      "Others               0.7955\n",
      "None                 0.9902\n",
      "\n",
      "Average accuracy per entity:             0.6967\n",
      "Overall accuracy (considering tokens):   0.9402\n",
      "-------------------------------------------------- \n",
      "\n",
      "Evaluating Bidirectional LSTM model: 21-BiLSTM_Loss_0.15430419193649092.pt\n",
      "\n",
      "Total time taken: 61.5034 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.7041\n",
      "Ross Geller          0.5952\n",
      "Chandler Bing        0.6387\n",
      "Monica Geller        0.6538\n",
      "Joey Tribbiani       0.6384\n",
      "Phoebe Buffay        0.6584\n",
      "Others               0.8025\n",
      "None                 0.9909\n",
      "\n",
      "Average accuracy per entity:             0.7102\n",
      "Overall accuracy (considering tokens):   0.9428\n",
      "-------------------------------------------------- \n",
      "\n",
      "Evaluating Bidirectional LSTM model: 31-BiLSTM_Loss_0.1387677234002888.pt\n",
      "\n",
      "Total time taken: 62.2397 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.7041\n",
      "Ross Geller          0.5833\n",
      "Chandler Bing        0.645\n",
      "Monica Geller        0.6538\n",
      "Joey Tribbiani       0.6374\n",
      "Phoebe Buffay        0.6658\n",
      "Others               0.8053\n",
      "None                 0.9906\n",
      "\n",
      "Average accuracy per entity:             0.7107\n",
      "Overall accuracy (considering tokens):   0.9427\n",
      "-------------------------------------------------- \n",
      "\n",
      "Evaluating Bidirectional LSTM model: 41-BiLSTM_Loss_0.1258366622119277.pt\n",
      "\n",
      "Total time taken: 59.7522 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.7108\n",
      "Ross Geller          0.5833\n",
      "Chandler Bing        0.6586\n",
      "Monica Geller        0.6617\n",
      "Joey Tribbiani       0.6406\n",
      "Phoebe Buffay        0.6683\n",
      "Others               0.7997\n",
      "None                 0.99\n",
      "\n",
      "Average accuracy per entity:             0.7141\n",
      "Overall accuracy (considering tokens):   0.9423\n",
      "-------------------------------------------------- \n",
      "\n",
      "Evaluating Bidirectional LSTM model: 51-BiLSTM_Loss_0.1138643277684236.pt\n",
      "\n",
      "Total time taken: 59.2077 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.6993\n",
      "Ross Geller          0.5761\n",
      "Chandler Bing        0.666\n",
      "Monica Geller        0.664\n",
      "Joey Tribbiani       0.6319\n",
      "Phoebe Buffay        0.6634\n",
      "Others               0.7948\n",
      "None                 0.9896\n",
      "\n",
      "Average accuracy per entity:             0.7106\n",
      "Overall accuracy (considering tokens):   0.9412\n",
      "-------------------------------------------------- \n",
      "\n",
      "Evaluating Bidirectional LSTM model: 61-BiLSTM_Loss_0.102537525134197.pt\n",
      "\n",
      "Total time taken: 61.5598 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.6908\n",
      "Ross Geller          0.5833\n",
      "Chandler Bing        0.6555\n",
      "Monica Geller        0.6674\n",
      "Joey Tribbiani       0.6276\n",
      "Phoebe Buffay        0.6683\n",
      "Others               0.7813\n",
      "None                 0.9892\n",
      "\n",
      "Average accuracy per entity:             0.7079\n",
      "Overall accuracy (considering tokens):   0.9398\n",
      "-------------------------------------------------- \n",
      "\n",
      "Evaluating Bidirectional LSTM model: 71-BiLSTM_Loss_0.09155423128380817.pt\n",
      "\n",
      "Total time taken: 65.5465 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.6984\n",
      "Ross Geller          0.5767\n",
      "Chandler Bing        0.6545\n",
      "Monica Geller        0.6686\n",
      "Joey Tribbiani       0.6363\n",
      "Phoebe Buffay        0.6547\n",
      "Others               0.7694\n",
      "None                 0.9884\n",
      "\n",
      "Average accuracy per entity:             0.7059\n",
      "Overall accuracy (considering tokens):   0.9382\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Bidirectional LSTM models\n",
    "\n",
    "#save_path = 'modelsV2/'\n",
    "save_path = 'models/'\n",
    "\n",
    "trained_models = os.listdir(save_path)\n",
    "trained_models = [t for t in trained_models if \"BiLSTM\" in t]\n",
    "\n",
    "best_dict, best_avg_dict = evaluate_models(model.BiLSTM, trained_models, \" Bidirectional LSTM model: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Best Average Accuracy Model BiLSTM: 41-BiLSTM_Loss_0.1258366622119277.pt \n",
      "\n",
      "Average accuracy per entity:             0.7141\n",
      "Overall accuracy (considering tokens):   0.9423\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rachel Green</th>\n",
       "      <th>Ross Geller</th>\n",
       "      <th>Chandler Bing</th>\n",
       "      <th>Monica Geller</th>\n",
       "      <th>Joey Tribbiani</th>\n",
       "      <th>Phoebe Buffay</th>\n",
       "      <th>Others</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rachel Green</th>\n",
       "      <td>747</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>198</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ross Geller</th>\n",
       "      <td>52</td>\n",
       "      <td>882</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>86</td>\n",
       "      <td>27</td>\n",
       "      <td>368</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chandler Bing</th>\n",
       "      <td>46</td>\n",
       "      <td>29</td>\n",
       "      <td>629</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>184</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monica Geller</th>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>581</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>151</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joey Tribbiani</th>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>590</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phoebe Buffay</th>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>540</td>\n",
       "      <td>136</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>162</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>27</td>\n",
       "      <td>101</td>\n",
       "      <td>51</td>\n",
       "      <td>3433</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>430</td>\n",
       "      <td>50111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Rachel Green  Ross Geller  Chandler Bing  Monica Geller  \\\n",
       "Rachel Green             747           29             14             10   \n",
       "Ross Geller               52          882             37             24   \n",
       "Chandler Bing             46           29            629             18   \n",
       "Monica Geller             45           24             28            581   \n",
       "Joey Tribbiani            55           51             19              7   \n",
       "Phoebe Buffay             41           26             20             17   \n",
       "Others                   162          100             63             27   \n",
       "None                      15           17              6             13   \n",
       "\n",
       "                Joey Tribbiani  Phoebe Buffay  Others   None  \n",
       "Rachel Green                21             16     198     16  \n",
       "Ross Geller                 86             27     368     36  \n",
       "Chandler Bing               15             14     184     20  \n",
       "Monica Geller               27              9     151     13  \n",
       "Joey Tribbiani             590             20     160     19  \n",
       "Phoebe Buffay               14            540     136     14  \n",
       "Others                     101             51    3433    356  \n",
       "None                        12             15     430  50111  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"***Best Average Accuracy Model BiLSTM:\", best_avg_dict[\"model_name\"], \"\\n\")\n",
    "\n",
    "print(\"{0:<40} {1:.4f}\".format(\"Average accuracy per entity: \", best_avg_dict[\"avg_accuracy\"]))\n",
    "print(\"{0:<40} {1:.4f}\\n\".format(\"Overall accuracy (considering tokens): \", best_avg_dict[\"accuracy\"]))\n",
    "\n",
    "pd.DataFrame(best_avg_dict[\"confusion_mat\"], columns = entities_dict.values(),index = entities_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Bi-LSTM model: \n",
      "\n",
      "Total time taken: 62.8041 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.71      0.67      1051\n",
      "          1       0.76      0.58      0.66      1512\n",
      "          2       0.77      0.66      0.71       955\n",
      "          3       0.83      0.66      0.74       878\n",
      "          4       0.68      0.64      0.66       921\n",
      "          5       0.78      0.67      0.72       808\n",
      "          6       0.68      0.80      0.73      4293\n",
      "          7       0.99      0.99      0.99     50619\n",
      "\n",
      "avg / total       0.94      0.94      0.94     61037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_path = 'models/'\n",
    "\n",
    "mo = model.BiLSTM(inp_dim, hidden_dim, n_classes)\n",
    "mo.load_state_dict(torch.load(save_path + \"41-BiLSTM_Loss_0.1258366622119277.pt\"))\n",
    "token_accuracy, avg_accuracy, accuracy_dict, confusion_mat, classification_rpt = evaluate(mo, \" Bi-LSTM model: \")\n",
    "\n",
    "print(classification_rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Normal LSTM model: 1000-SimpleLSTM_FinalLoss_1.018389134275678e-05.pt\n",
      "\n",
      "Total time taken: 32.7453 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.4215\n",
      "Ross Geller          0.2937\n",
      "Chandler Bing        0.4335\n",
      "Monica Geller        0.0911\n",
      "Joey Tribbiani       0.0456\n",
      "Phoebe Buffay        0.0347\n",
      "Others               0.181\n",
      "None                 0.9786\n",
      "\n",
      "Average accuracy per entity:             0.3100\n",
      "Overall accuracy (considering tokens):   0.8481\n",
      "-------------------------------------------------- \n",
      "\n",
      "Evaluating Normal LSTM model: SimpleLSTM_FinalLoss_0.10881423137443184.pt\n",
      "\n",
      "Total time taken: 30.8198 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.7298\n",
      "Ross Geller          0.75\n",
      "Chandler Bing        0.7183\n",
      "Monica Geller        0.705\n",
      "Joey Tribbiani       0.7481\n",
      "Phoebe Buffay        0.7116\n",
      "Others               0.8185\n",
      "None                 0.9942\n",
      "\n",
      "Average accuracy per entity:             0.7719\n",
      "Overall accuracy (considering tokens):   0.9553\n",
      "-------------------------------------------------- \n",
      "\n",
      "Evaluating Normal LSTM model: SimpleLSTM_FinalLoss_0.11093811956997775.pt\n",
      "\n",
      "Total time taken: 35.9187 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.7336\n",
      "Ross Geller          0.7315\n",
      "Chandler Bing        0.6974\n",
      "Monica Geller        0.6629\n",
      "Joey Tribbiani       0.7112\n",
      "Phoebe Buffay        0.6955\n",
      "Others               0.8137\n",
      "None                 0.9929\n",
      "\n",
      "Average accuracy per entity:             0.7548\n",
      "Overall accuracy (considering tokens):   0.9518\n",
      "-------------------------------------------------- \n",
      "\n",
      "Evaluating Normal LSTM model: SimpleLSTM_FinalLoss_0.20282605748573695.pt\n",
      "\n",
      "Total time taken: 36.4094 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.5737\n",
      "Ross Geller          0.7077\n",
      "Chandler Bing        0.7173\n",
      "Monica Geller        0.6173\n",
      "Joey Tribbiani       0.6004\n",
      "Phoebe Buffay        0.6559\n",
      "Others               0.7612\n",
      "None                 0.9907\n",
      "\n",
      "Average accuracy per entity:             0.7030\n",
      "Overall accuracy (considering tokens):   0.9404\n",
      "-------------------------------------------------- \n",
      "\n",
      "Evaluating Normal LSTM model: SimpleLSTM_FinalLoss_0.21003304342390275.pt\n",
      "\n",
      "Total time taken: 34.1023 seconds.\n",
      "\n",
      "*****Accuracy for each entity:*****\n",
      "Rachel Green         0.5699\n",
      "Ross Geller          0.7196\n",
      "Chandler Bing        0.7162\n",
      "Monica Geller        0.615\n",
      "Joey Tribbiani       0.5993\n",
      "Phoebe Buffay        0.6498\n",
      "Others               0.7086\n",
      "None                 0.9937\n",
      "\n",
      "Average accuracy per entity:             0.6965\n",
      "Overall accuracy (considering tokens):   0.9392\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluating Normal LSTM models\n",
    "\n",
    "trained_models = os.listdir(save_path)\n",
    "trained_models = [t for t in trained_models if \"SimpleLSTM\" in t]\n",
    "\n",
    "best_dict_S, best_avg_dict_S = evaluate_models(model.SimpleLSTM, trained_models, \" Normal LSTM model: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Best Average Accuracy Model LSTM: SimpleLSTM_FinalLoss_0.10881423137443184.pt \n",
      "\n",
      "Average accuracy per entity:             0.7719\n",
      "Overall accuracy (considering tokens):   0.9553\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rachel Green</th>\n",
       "      <th>Ross Geller</th>\n",
       "      <th>Chandler Bing</th>\n",
       "      <th>Monica Geller</th>\n",
       "      <th>Joey Tribbiani</th>\n",
       "      <th>Phoebe Buffay</th>\n",
       "      <th>Others</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rachel Green</th>\n",
       "      <td>767</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>114</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ross Geller</th>\n",
       "      <td>23</td>\n",
       "      <td>1134</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>91</td>\n",
       "      <td>15</td>\n",
       "      <td>178</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chandler Bing</th>\n",
       "      <td>25</td>\n",
       "      <td>102</td>\n",
       "      <td>686</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>79</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monica Geller</th>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>619</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joey Tribbiani</th>\n",
       "      <td>33</td>\n",
       "      <td>76</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>689</td>\n",
       "      <td>12</td>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phoebe Buffay</th>\n",
       "      <td>23</td>\n",
       "      <td>77</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>575</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>98</td>\n",
       "      <td>231</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>115</td>\n",
       "      <td>38</td>\n",
       "      <td>3514</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>235</td>\n",
       "      <td>50326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Rachel Green  Ross Geller  Chandler Bing  Monica Geller  \\\n",
       "Rachel Green             767           71              8             22   \n",
       "Ross Geller               23         1134             28             20   \n",
       "Chandler Bing             25          102            686             16   \n",
       "Monica Geller             40           70             12            619   \n",
       "Joey Tribbiani            33           76             11              7   \n",
       "Phoebe Buffay             23           77             18             12   \n",
       "Others                    98          231             32             24   \n",
       "None                       9           18             15              8   \n",
       "\n",
       "                Joey Tribbiani  Phoebe Buffay  Others   None  \n",
       "Rachel Green                39             10     114     20  \n",
       "Ross Geller                 91             15     178     23  \n",
       "Chandler Bing               25             10      79     12  \n",
       "Monica Geller               33              6      86     12  \n",
       "Joey Tribbiani             689             12      83     10  \n",
       "Phoebe Buffay               29            575      67      7  \n",
       "Others                     115             38    3514    241  \n",
       "None                         5              3     235  50326  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"***Best Average Accuracy Model LSTM:\", best_avg_dict_S[\"model_name\"], \"\\n\")\n",
    "\n",
    "print(\"{0:<40} {1:.4f}\".format(\"Average accuracy per entity: \", best_avg_dict_S[\"avg_accuracy\"]))\n",
    "print(\"{0:<40} {1:.4f}\\n\".format(\"Overall accuracy (considering tokens): \", best_avg_dict_S[\"accuracy\"]))\n",
    "\n",
    "pd.DataFrame(best_avg_dict_S[\"confusion_mat\"], columns = entities_dict.values(),index = entities_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LSTM model: \n",
      "\n",
      "Total time taken: 37.9662 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.73      0.74      1051\n",
      "          1       0.64      0.75      0.69      1512\n",
      "          2       0.85      0.72      0.78       955\n",
      "          3       0.85      0.71      0.77       878\n",
      "          4       0.67      0.75      0.71       921\n",
      "          5       0.86      0.71      0.78       808\n",
      "          6       0.81      0.82      0.81      4293\n",
      "          7       0.99      0.99      0.99     50619\n",
      "\n",
      "avg / total       0.96      0.96      0.96     61037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_path = 'models/'\n",
    "\n",
    "mo = model.SimpleLSTM(inp_dim, hidden_dim, n_classes)\n",
    "mo.load_state_dict(torch.load(save_path + \"SimpleLSTM_FinalLoss_0.10881423137443184.pt\"))\n",
    "token_accuracy, avg_accuracy, accuracy_dict, confusion_mat, classification_rpt = evaluate(mo, \" LSTM model: \")\n",
    "\n",
    "print(classification_rpt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
